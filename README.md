# LearnAssist â€“ Subject Guide & Q-Bank AI Assistant

ğŸš€ **LearnAssist** is an AI-powered study companion that helps students analyze documents, generate question banks, create notes, summarize content, and extract insights from multi-format files â€” all inside a clean, fast Streamlit interface.

It supports:
- ğŸ“„ **PDFs**
- ğŸ“ **DOCX**
- ğŸ–¼ï¸ **Images (JPG, PNG, WEBP, JPEG)**
- ğŸ“Š **PPTX**
- ğŸ§  **Text-based Q&A, Summaries & Notes**

LearnAssist is built using a **multi-agent architecture**, allowing smart delegation between:
- Notes Agent  
- Summary Agent  
- QA Agent  
- Question Generation Agent  
- Intent Detection Agent  
- Small-talk Agent  
- Orchestrator Agent  

---

## ğŸš€ Live Demo
[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://yash158-stack-ai-agent-app-kvirlu.streamlit.app/)

---

## ğŸ“¦ Features

### ğŸ” Intelligent File Analysis
Upload **PDF, DOCX, PPTX, PNG, JPG, WEBP**, and get:
- Topic summaries  
- Question banks (MCQs, short & long answers)  
- Structured notes  
- Definitions, keywords, explanations  

---

### ğŸ¤– Multi-Agent System
Each task is handled by a dedicated agent:
- `notes_agent.py` â†’ Creates clean notes  
- `summary_agent.py` â†’ Compresses long documents  
- `qa_agent.py` â†’ Answers questions from uploaded files  
- `question_agent.py` â†’ Generates exam-style questions  
- `intent_agent.py` â†’ Understands the user's request  
- `orchestrator.py` â†’ Routes queries to the right agent  

---

### ğŸ“ Vector Storage (FAISS)
- Stores embeddings of document chunks  
- Enables fast semantic retrieval (RAG)  
- Uses HuggingFace Sentence Transformers  

---

### ğŸ—„ï¸ Semantic Response Caching (NEW)
- AI-generated responses are **persisted** using SQLite  
- Each user query is converted into a **vector embedding**  
- New queries are compared using **semantic similarity**  
- If a similar query already exists:
  - Cached response is returned instantly  
  - âŒ LLM is NOT called  
  - âš¡ Faster response & reduced API usage  

This creates a **shared academic knowledge base** where future users benefit from previous queries.

---

## ğŸ”§ Tech Stack
- Python  
- Streamlit  
- Gemini (google-generativeai)  
- LangChain (core, community, text-splitters, HF embeddings)  
- Sentence Transformers  
- FAISS  
- SQLite + SQLAlchemy (Semantic Cache)  
- python-docx  
- pdfplumber / PyPDF2  
- python-pptx  
- pytesseract (OCR)  
- Pillow  
- NumPy, Pandas  

---

## ğŸ§  System Architecture

LearnAssist follows a hybrid AI architecture:

1. **FAISS Vector Store**
   - Stores embeddings of document chunks  
   - Used for Retrieval-Augmented Generation (RAG)  

2. **SQLite Semantic Cache**
   - Stores:
     - User queries  
     - Query embeddings  
     - AI-generated responses  
   - Prevents repeated LLM calls for similar queries  

3. **Multi-Agent Orchestrator**
   - Detects user intent  
   - Routes requests to specialized agents  
   - Combines document context, cached knowledge, and LLM reasoning  

This design ensures:
- High performance  
- Cost efficiency  
- Consistent academic explanations  

---

## ğŸ“‚ Project Structure

AI-AGENT/
â”œâ”€â”€ pycache/
â”œâ”€â”€ .devcontainer/
â”œâ”€â”€ .streamlit/
â”‚ â””â”€â”€ config.toml
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ intent_agent.py
â”‚ â”œâ”€â”€ keywords.py
â”‚ â”œâ”€â”€ notes_agent.py
â”‚ â”œâ”€â”€ orchestrator.py
â”‚ â”œâ”€â”€ prompts.py
â”‚ â”œâ”€â”€ qa_agent.py
â”‚ â”œâ”€â”€ question_agent.py
â”‚ â”œâ”€â”€ smalltalk_agent.py
â”‚ â””â”€â”€ summary_agent.py
â”œâ”€â”€ faiss_db/
â”œâ”€â”€ user_data/
â”œâ”€â”€ venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py
â”œâ”€â”€ chat_engine.py
â”œâ”€â”€ ingest.py
â”œâ”€â”€ cache.py
â”œâ”€â”€ db.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt
â””â”€â”€ README.md

---

## âš™ï¸ Setup Guide (For Users & Developers)

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>

python -m venv venv
source venv/bin/activate   # Mac & Linux
venv\Scripts\activate      # Windows

pip install -r requirements.txt

GEMINI_API_KEY=your_key_here

streamlit run app.py
App runs at â†’ http://localhost:8501

```

ğŸ“Š Database & Caching Behavior

Uses a global SQLite database (learn_assist.db)
- Cached responses are shared across users
- Query similarity is determined using cosine similarity on embeddings
- On semantic cache hit:
    - Stored response is returned
    - LLM is not invoked
- This significantly reduces latency and API usage for repeated academic queries.
---

ğŸ–¼ Screenshots
ğŸ“Œ Home Page

(Add screenshot)

ğŸ“Œ File Upload & Processing

(Add screenshot)

ğŸ“Œ AI Summary / Questions / Notes

(Add screenshot)

ğŸ“Œ Semantic Cache (SQLite)

(Add DB Browser screenshot showing cached queries and responses)
---
â¤ï¸ Acknowledgements

LearnAssist is developed with the goal of helping learners interact with complex academic material in a clear, intelligent, and efficient way.

It demonstrates how Retrieval-Augmented Generation and semantic caching can be combined to build scalable AI learning systems.